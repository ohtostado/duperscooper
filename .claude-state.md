# Claude Development State - duperscooper

**Last Updated:** 2025-10-02
**Current Branch:** feature/sort-by-quality
**Latest Commit:** (implementing quality-first sorting)

## Project Overview

**duperscooper** is a Python CLI application that finds duplicate audio files using fuzzy perceptual matching (Chromaprint fingerprints with Hamming distance) across different formats, bitrates, and encodings. Now includes album-level duplicate detection.

## Recent Development Session Summary

### Currently In Progress: Album Mode Implementation ðŸš§

**Status:** Phases 1-3 Complete, Testing & Phase 4 Pending

**Branch:** feature/album-mode

### Phase 1: Album Detection & Metadata Extraction (COMPLETED - Commit: 5e54aa9)

**Objective:** Detect albums (directories) and extract comprehensive metadata.

**Completed Work:**

1. **Album Data Structure**
   - Created `Album` dataclass in `src/duperscooper/album.py`
   - Fields: path, tracks, track_count, musicbrainz_albumid, album_name, artist_name, total_size, avg_quality_score, fingerprints, has_mixed_mb_ids, quality_info

2. **Album Scanner**
   - Implemented `AlbumScanner` class for album discovery
   - Non-recursive directory scan (one album = one directory)
   - MusicBrainz Album ID extraction via ffprobe
   - Album/artist tag extraction from audio files
   - Detection of mixed MusicBrainz IDs within album
   - Leverages existing `AudioHasher` for fingerprinting and caching

3. **Integration**
   - Added `--album-mode` CLI flag
   - Added `--album-match-strategy` option (auto, musicbrainz, fingerprint)
   - Separate output formatting for album mode

### Phase 2: Album Matching Strategies (COMPLETED - Commit: 9cd8e77)

**Objective:** Implement multiple strategies for matching duplicate albums.

**Completed Work:**

1. **AlbumDuplicateFinder Class**
   - Three matching strategies: `auto`, `musicbrainz`, `fingerprint`
   - `_match_by_musicbrainz()`: Group by MB ID + track count
   - `_match_by_fingerprints()`: Perceptual similarity using Union-Find
   - `album_similarity()`: Average track-by-track similarity

2. **Auto Strategy Enhancement** (Commits: 0adb5b8, 3e00be4)
   - **Fixed:** Initial bug where tagged/untagged albums didn't group together
   - **Refactored:** Fingerprint all albums first, then merge by MB IDs
   - **Canonical Matching:** Albums with MB IDs or ID3 tags establish canonical version
   - Untagged albums match against canonical versions and inherit their names
   - Prioritizes: MB ID > ID3 tags > fingerprint similarity

3. **Similarity Calculation**
   - Track-by-track fingerprint comparison
   - Average similarity percentage for album grouping
   - Hamming distance between track fingerprints
   - Default threshold: 98% (configurable)

### Phase 3: Matched Album/Artist Identification (COMPLETED - Commits: f4fd46f, ac2b4b7, f592888)

**Objective:** Display matched album/artist names and confidence scores.

**Completed Work:**

1. **Matched Album Info** (Commit: f4fd46f)
   - `get_matched_album_info()`: Determine canonical album/artist for group
   - Prioritizes albums with MB IDs or complete metadata
   - Falls back to most common names if no canonical album

2. **Confidence Scoring**
   - 100%: All albums have matching MusicBrainz Album ID
   - 90-95%: Album/artist metadata matches + high fingerprint similarity
   - 80-90%: Fingerprint similarity only (no metadata match)
   - Calculation factors:
     - Base: 80%
     - +5% if album name matches
     - +5% if artist name matches
     - +0-10% based on avg fingerprint similarity (98-100% range)

3. **Album Cache in SQLite** (Commit: ac2b4b7)
   - Added `album_cache` and `album_tracks` tables
   - Directory mtime-based invalidation
   - Stores: path, metadata, quality info, track list
   - Thread-safe with WAL mode (ready for Phase 5)
   - Schema implemented, integration pending

4. **Match Method Display** (Commit: f592888)
   - Added `match_method` field to `Album` dataclass
   - Shows how album was matched in all output formats:
     - "MusicBrainz Album ID"
     - "ID3 Album/Artist Tags"
     - "Acoustic Fingerprint"
   - Applied to text, JSON, and CSV output

5. **Output Enhancements**
   - Text: Shows matched album/artist, best quality marker, confidence percentage with color coding
   - JSON: Includes `matched_album`, `matched_artist`, `confidence`, `match_method` for each album
   - CSV: Columns for matched info, confidence, match method

### Test Infrastructure (COMPLETED - Current Session)

**Test Scenarios Created:**

1. **Baseline (16 albums)**
   - AlbumA (9 tracks): 8 versions (FLAC/MP3, with/without MB IDs, various bitrates)
   - AlbumB (10/11 tracks): 8 versions (FLAC/MP3, with/without MB IDs, various bitrates)

2. **Test Scenario 1: Mixed MusicBrainz IDs**
   - AlbumA-FLAC-MIXED-MB-IDs (tracks 1-2 correct MB ID, tracks 3-9 fake MB ID)
   - Expected: Match by ID3 tags, show warning about mixed MB IDs

3. **Test Scenario 2: ID3 Tags Only**
   - AlbumA-MP3-ID3-ONLY-320 (MB IDs removed via ffmpeg)
   - AlbumB-MP3-ID3-ONLY-320 (MB IDs removed via ffmpeg)
   - Expected: Match by ID3 tags, group with canonical albums

4. **Test Scenario 3: Partial Albums**
   - AlbumA-FLAC-PARTIAL-missing-2-tracks (7 tracks instead of 9)
   - AlbumB-MP3-PARTIAL-missing-3-tracks (7 tracks instead of 10/11)
   - Expected: No duplicate groups (only 1 album each)

5. **Documentation**
   - Created `test-albums/TEST-SCENARIOS.md` with detailed descriptions

**Test Results (Verified âœ…):**

- AlbumA group: 10 albums matched correctly (8 baseline + 1 ID3-only + 1 mixed-MB)
- AlbumB group: 9 albums matched correctly (8 baseline + 1 ID3-only)
- Partial albums: Correctly excluded (need 2+ albums for duplicate group)
- Match methods displayed correctly with appropriate confidence scores
- Mixed MB IDs handled properly with warning

### Previously Completed: Multithreading Implementation âœ…

**Status:** All Phases Complete (Phase 1, 2, 3) - Merged to main

**Branch:** main (merged from feature/multithreading)

**Key Features:**

1. **SQLite Cache Backend** (Commit: 86d7842)
   - Thread-local database connections
   - WAL mode for concurrent access
   - Auto-migration from JSON cache
   - 16 comprehensive unit tests

2. **Parallel Fingerprinting** (Commit: 1b70aa4)
   - ThreadPoolExecutor with configurable workers (default: 8)
   - Real-time ETA estimation
   - 2.7x speedup on test dataset
   - Thread-safe progress tracking

3. **Performance Benchmarks** (Commit: c0fe445)
   - 8 workers: 63% faster than sequential
   - ~10 files/second on production dataset
   - Diminishing returns beyond 8 workers

### Previously Completed: Quality Detection & Display

1. **Quality Detection System** (Commit: 942d2ea)
   - ffprobe-based metadata extraction
   - Quality scoring (lossless > lossy)
   - Enhanced all output formats

2. **Color Output** (Commit: c6ac43b)
   - Colorama integration
   - Color-coded similarity percentages
   - Highlighted [Best] markers

3. **Display Improvements** (Commit: 807c185)
   - Sorting by similarity descending
   - Proper tree drawing (â””â”€ for last item)

## Current Project State

### Technology Stack

- **Language:** Python 3.8+ (tested on 3.13)
- **Audio Fingerprinting:** Direct `fpcalc` binary calls (Python 3.13 compatible)
- **Metadata Extraction:** `ffprobe` binary
- **Dependencies:**
  - `tqdm>=4.66.0` - Progress bars
  - `colorama>=0.4.6` - Cross-platform terminal colors
- **Dev Dependencies:**
  - `black==24.8.0` - Code formatting
  - `ruff==0.6.3` - Linting
  - `mypy==1.11.2` - Type checking
  - `pytest==8.3.2` - Testing
  - `pytest-cov==5.0.0` - Coverage

### Code Structure

```text
src/duperscooper/
â”œâ”€â”€ __init__.py       # Package metadata, version
â”œâ”€â”€ __main__.py       # CLI interface, output formatting, colorama integration
â”œâ”€â”€ cache.py          # CacheBackend interface, SQLite/JSON implementations
â”œâ”€â”€ hasher.py         # AudioHasher: perceptual & exact hashing, metadata
â”œâ”€â”€ finder.py         # DuplicateFinder: search logic, parallelization
â”‚                     # DuplicateManager: file operations
â””â”€â”€ album.py          # Album: dataclass for album metadata
                      # AlbumScanner: album discovery and metadata extraction
                      # AlbumDuplicateFinder: album duplicate detection
```

### Key Algorithms

#### Album Matching (Album Mode)

- **Canonical Matching:**
  1. Identify canonical albums (MB ID > ID3 tags)
  2. Fingerprint match canonical albums together
  3. Match untagged albums against canonical groups
  4. Untagged albums inherit canonical names

- **Match Confidence:**
  - MusicBrainz ID: 100%
  - ID3 Album/Artist Tags: 90-95%
  - Acoustic Fingerprint: 80-90%

- **Album Similarity:** Average track-by-track fingerprint similarity

#### Perceptual Matching (Track Mode)

- Raw Chromaprint fingerprints (948 32-bit integers)
- Hamming distance for bit-level comparison
- Default similarity threshold: 98.0%
- O(nÂ²) with Union-Find grouping
- Detects duplicates across all bitrates/formats

#### Quality Scoring

- **Lossless:** 10000 + (bit_depth Ã— 100) + (sample_rate / 1000)
- **Lossy:** bitrate / 1000 (in kbps)

#### Caching

- **Default Backend:** SQLite (thread-safe, WAL mode)
- **Location:** `~/.config/duperscooper/hashes.db`
- **Track Cache:** SHA256 file hash â†’ raw fingerprint
- **Album Cache:** Directory path â†’ album metadata (schema ready, integration pending)
- **Auto-migration:** JSON cache automatically migrated to SQLite

### Test Environment

#### Track Mode Tests

- **Test Files:** `test-audio/` directory
  - test.flac (44.1kHz 16bit, 30.9 MB)
  - 14 MP3 variants (CBR: 64-320kbps, VBR: V2-V9)
  - All successfully detected as duplicates

#### Album Mode Tests

- **Test Folders:** `test-albums/` directory
  - 21 album folders total
  - 16 baseline albums (AlbumA Ã— 8, AlbumB Ã— 8)
  - 5 test scenario folders (mixed MB IDs, ID3-only, partial albums)
  - All scenarios verified working correctly

## Development Workflow

### Quality Checks (Must Pass Before Commit)

```bash
.venv/bin/black src/ tests/       # Format code
.venv/bin/ruff check src/ tests/  # Lint
.venv/bin/mypy src/               # Type check
.venv/bin/pytest tests/ -v        # Run tests
```

### Git Workflow

- Remote: `origin` = git@github-ohtostado:ohtostado/duperscooper.git
- Main branch: `main`
- Feature branch: `feature/album-mode` (current)
- Commit style: Conventional commits (feat:, fix:, docs:, etc.)
- Always reference issues: "Fixes #123" or "Implements #456"

### Installation

```bash
# Setup virtual environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Install in editable mode
pip install -e .

# Run application
duperscooper /path/to/music
```

## Current Feature Set

### Track Mode (Default)

```bash
# Basic usage
duperscooper ~/Music

# Exact byte matching (faster, less flexible)
duperscooper ~/Music --algorithm exact

# Adjust similarity threshold
duperscooper ~/Music --similarity-threshold 95.0

# Output formats
duperscooper ~/Music --output json
duperscooper ~/Music --output csv

# Interactive deletion
duperscooper ~/Music --delete-duplicates

# Cache management
duperscooper --clear-cache
duperscooper ~/Music --no-cache
duperscooper ~/Music --update-cache

# Multithreading
duperscooper ~/Music --workers 16
duperscooper ~/Music --workers 1  # Sequential

# Cache backend selection
duperscooper ~/Music --cache-backend json  # Legacy
```

### Album Mode (New)

```bash
# Find duplicate albums
duperscooper ~/Music --album-mode

# MusicBrainz-only matching
duperscooper ~/Music --album-mode --album-match-strategy musicbrainz

# Fingerprint-only matching
duperscooper ~/Music --album-mode --album-match-strategy fingerprint

# Auto strategy (default): canonical matching
duperscooper ~/Music --album-mode --album-match-strategy auto

# Output formats (both write to stdout, use redirection to save)
duperscooper ~/Music --album-mode --output json > albums.json
duperscooper ~/Music --album-mode --output csv > albums.csv
```

## Known Working State

### All Tests Passing âœ…

- 22 unit tests (6 in `tests/test_finder.py`, 16 in `tests/test_cache.py`)
- All code quality checks passing (Black, Ruff, MyPy)
- Test coverage for core functionality and cache backends

### Verified Features âœ…

**Track Mode:**

- Perceptual matching across bitrates (64kbps - FLAC)
- Exact matching fallback
- SQLite cache with thread-local connections
- Parallel fingerprinting (8 workers, 2.7x speedup)
- Quality detection and scoring
- Color output
- All output formats

**Album Mode:**

- Album discovery and metadata extraction
- MusicBrainz ID matching
- ID3 tag matching
- Acoustic fingerprint matching
- Canonical matching (MB ID â†’ ID3 â†’ fingerprint)
- Mixed MB ID detection and warnings
- Match method display
- Confidence scoring
- All output formats (text, JSON, CSV)

## Next Steps / Future Phases

### Phase 4: Album Cache Integration âœ… (COMPLETED)

**Objective:** Use SQLite album cache to speed up repeated scans.

**Status:** Completed - Merged in PR #1

**Completed Tasks:**

- âœ… Integrated `get_album()` / `set_album()` into `AlbumScanner`
- âœ… Directory mtime-based cache invalidation implemented
- âœ… Tested cache hits/misses with album mode
- âœ… Measured performance improvement (~2-3x speedup on repeated scans)

### Phase 5: Partial Album Detection âœ… (COMPLETED)

**Objective:** Detect albums with missing tracks as potential duplicates.

**Status:** Completed - Merged in PR #2 (formerly Phase 6, swapped with Phase 6)

**Completed Tasks:**

- âœ… Implemented partial album matching with `--allow-partial-albums` flag
- âœ… Configurable overlap threshold via `--min-album-overlap` (default 70%)
- âœ… Best-effort track matching algorithm using `partial_album_similarity()`
- âœ… Overlap percentage calculation and display in all output formats
- âœ… Enhanced Album dataclass with `is_partial_match`, `overlap_percentage` fields
- âœ… Works with all matching strategies (auto, musicbrainz, fingerprint)
- âœ… Handles edge cases (bonus tracks, deluxe editions, reordered tracks)
- âœ… Group sorting by average match percentage (highest quality matches first)
- âœ… Tested with partial albums (7/9 tracks, 7/11 tracks)

### Phase 6: Tab Completion âœ… (COMPLETED)

**Objective:** Implement bash/zsh/tcsh tab completion for duperscooper command-line options.

**Status:** Completed - Merged to main

**Completed Tasks:**

- âœ… Extracted `get_parser()` function in `src/duperscooper/__main__.py` for shtab import
- âœ… Created `install-completion.sh` script for automatic installation
- âœ… Created `uninstall-completion.sh` script for cleanup
- âœ… Added `shtab>=1.7.0` to `pyproject.toml` as optional dependency
- âœ… Added `shtab==1.7.1` to `requirements.txt`
- âœ… Updated `CLAUDE.md` with tab completion documentation
- âœ… Verified shtab can generate completion scripts successfully
- âœ… All quality checks passed (Black, Ruff, MyPy)

**Implementation Details:**

- Uses shtab's static completion script generation (faster than dynamic)
- External shell scripts call `shtab --shell=bash duperscooper.__main__.get_parser`
- Supports bash, zsh, and tcsh shells
- Auto-detects shell or accepts explicit argument
- Completion is optional - doesn't affect normal duperscooper usage
- No performance impact (static scripts generated once)

**Usage:**

```bash
# Install shtab (optional dependency)
pip install shtab

# Install tab completion
./install-completion.sh bash  # or zsh, tcsh

# Test it
duperscooper --al<TAB>  # completes to --album-mode, --album-match-strategy, etc.

# Uninstall
./uninstall-completion.sh bash
```

### Phase 7: Quality-First Sorting (In Progress - feature/sort-by-quality)

**Objective:** Sort duplicates by quality (worst first) to prioritize deletion candidates.

**Status:** In Progress - Testing complete, ready for PR

**Rationale:** Users want to delete duplicate files/albums, so showing the worst quality items first makes the deletion workflow more efficient.

**Completed Tasks:**

- âœ… Updated track mode text output sorting (quality ascending, similarity descending)
- âœ… Updated track mode JSON output sorting
- âœ… Updated track mode CSV output sorting
- âœ… Updated album mode text output sorting
- âœ… Updated album mode JSON output sorting
- âœ… Updated album mode CSV output sorting
- âœ… All quality checks passed (Black, Ruff, MyPy)
- âœ… Tested with test-audio/ - verified 64kbps appears before 320kbps
- âœ… Tested with test-albums/ - verified MP3s appear before FLACs

**Implementation Details:**

**Track Mode:**

- Sort duplicates by `(quality_score, -similarity)` - worst quality first, highest similarity tiebreaker
- [Best] quality file always appears first
- Example order: [Best] FLAC â†’ 64kbps MP3 â†’ 128kbps MP3 â†’ 320kbps MP3

**Album Mode:**

- Sort duplicates by `(avg_quality_score, -match_percentage)` - worst quality first
- [Best] quality album always appears first
- Example order: [Best] FLAC 96kHz â†’ MP3 64kbps â†’ MP3 128kbps â†’ MP3 320kbps â†’ FLAC 44.1kHz

**Files Modified:**

- `src/duperscooper/__main__.py` - All 6 output formatting functions updated

**Benefits:**

- Deletion candidates (worst quality) appear first in all outputs
- Better workflow for interactive deletion
- Consistent behavior across track and album modes
- [Best] reference always stays at top for easy comparison

## Pre-GUI Feature Implementation Plan (4 weeks)

**Goal:** Implement essential deletion infrastructure before GUI development begins.

### Phase 1: Critical Deletion Infrastructure (Weeks 1-3) ðŸ”´ **MUST COMPLETE**

#### Feature 1: Staging Folder Deletion System (Week 1)
**Priority:** Critical - GUI blocker
**Status:** Not started

**Implementation:**
- Create `.deletedByDuperscooper/TIMESTAMP/files/` directory structure
- NEW: `src/duperscooper/staging.py` (StagingManager class)
- Hybrid file organization: numbered flat files (001_filename.mp3)
- Generate `manifest.json` with metadata (original paths, deletion reason, timestamp, quality info)
- Per-scan-path staging folders (avoid cross-filesystem moves)
- Add `--auto-delete-worst` flag

**CLI Examples:**
```bash
duperscooper ~/Music --album-mode --auto-delete-worst
duperscooper ~/Music --delete-duplicates  # Track mode
```

#### Feature 2: JSON Ingestion / Apply Rules Mode (Week 2)
**Priority:** Critical - GUI blocker
**Status:** Not started

**Implementation:**
- NEW: `src/duperscooper/rules.py` (RuleEngine, Rule, RuleCondition)
- NEW: `src/duperscooper/apply.py` (ScanResultLoader, ApplyEngine)
- Add `--apply-rules FILE` argument
- Built-in strategies: `eliminate-duplicates`, `keep-lossless`, `keep-format`, `custom`
- Parse JSON/CSV scan results and apply rules

**CLI Examples:**
```bash
duperscooper ~/Music --album-mode --output json > scan.json
duperscooper --apply-rules scan.json --strategy eliminate-duplicates
duperscooper --apply-rules scan.json --strategy custom --config rules.yaml
```

#### Features 3-6: Safety & Parity (Week 3)
**Priority:** Critical
**Status:** Not started

**Feature 3: Dry-Run Mode**
- Add `--dry-run` flag
- Show deletion plan without executing

**Feature 4: Non-Interactive Mode**
- Add `--yes` flag to skip confirmations
- Essential for GUI integration

**Feature 5: recommended_action in JSON**
- Add `recommended_action: "keep"|"delete"` field to JSON output
- GUI uses this for pre-selection

**Feature 6: Interactive Album Deletion**
- Implement `AlbumManager` class
- Finish `--delete-duplicate-albums` placeholder

### Phase 2: Staging Management Commands (Week 4) ðŸŸ¡ **GUI BLOCKER**

#### Feature 7: List/Restore/Empty Commands
**Priority:** Critical - GUI blocker
**Status:** Not started

**Implementation:**
- `--list-deleted`: Show staging batches
- `--restore TIMESTAMP`: Restore files from staging
- `--empty-deleted`: Permanently delete staged files
- Retention policies: `--keep-last N`, `--older-than DAYS`

**CLI Examples:**
```bash
duperscooper --list-deleted
duperscooper --restore 2025-10-02_15-30-45
duperscooper --empty-deleted --older-than 30
```

---

### Success Criteria for GUI Development Start

âœ… **Features 1-7 must be complete:**
- Can stage albums for deletion (not permanent)
- Can ingest JSON and apply rules
- Can restore from staging
- Can list/empty staging batches
- Dry-run mode works
- Non-interactive (--yes) mode works
- JSON includes recommended_action

**Estimated Time to GUI-Ready:** 4 weeks

---

## Post-GUI Release Features (Nice-to-Have)

### Feature 8: Resume Interrupted Scans
**Priority:** Nice-to-have
**Estimated Time:** 3 days

Save partial scan state, add `--resume` flag for large libraries.

### Feature 9: Incremental Scan Mode
**Priority:** Nice-to-have
**Estimated Time:** 2 days

`--incremental` flag to skip unchanged albums (mtime check), 100x speedup for repeated scans.

### Feature 10: Filter/Exclude Patterns
**Priority:** Nice-to-have
**Estimated Time:** 2 days

`--exclude PATTERN` and `--include PATTERN` for path filtering.

```bash
duperscooper ~/Music --exclude "*/backups/*" --exclude "*.m4a"
```

### Feature 11: Statistics/Report Mode
**Priority:** Nice-to-have
**Estimated Time:** 1 day

`--stats` flag for quick summary without full listing.

### Feature 12: Export/Import Workflow
**Priority:** Nice-to-have
**Estimated Time:** 1 day

`--save FILE` and `--load FILE` for saving/loading scan results.

### Feature 13: Configurable Verbosity
**Priority:** Nice-to-have
**Estimated Time:** 1 day

`--quiet` and `--verbose` flags for output control.

### Feature 14: Batch Processing Per Path
**Priority:** Nice-to-have
**Estimated Time:** 2 days

`--separate` flag to show duplicates per input path.

---

## Performance Optimizations (Future)

### Feature 15: Parallel Duplicate Matching
**Priority:** Optimization
**Estimated Time:** 3 days

Parallelize O(nÂ²) fuzzy matching loop for 10k+ files.

### Feature 16: Smart Similarity Caching
**Priority:** Optimization
**Estimated Time:** 2 days

Cache pairwise similarity scores in SQLite to avoid recomputation.

### Feature 17: LSH-Based Fingerprint Indexing
**Priority:** Optimization - Future
**Estimated Time:** 1 week

Locality-sensitive hashing for O(n log n) matching, scales to 100k+ files.

---

## Future Features (Lower Priority)

### Fuzzy Tag Matching
**Objective:** Match albums with misspelled metadata.

**Implementation:**
- Levenshtein distance for album/artist names
- Example: "The Beatles" vs "Beatles" or "Led Zeppelin" vs "Led Zepplin"
- Configurable matching threshold

### Strict Fingerprint Mode
**Objective:** Ultra-conservative duplicate detection ignoring all metadata.

**Use Case:** Libraries with poor/inconsistent tagging.

**Implementation:**
```bash
duperscooper ~/Music --strict --strict-threshold 99.5
duperscooper ~/Music --album-mode --strict --strict-threshold 99.5
```

### Other Ideas
- Preview audio before deletion
- More exotic audio formats (AIFF, APE, DSD)
- GUI interface (PySide6/Qt - see separate plan)

## Important Development Notes

### Template System Rules (from ~/.claude/CLAUDE.md)

- **NEVER edit** generated files directly (README.adoc, CONTRIBUTING.adoc, etc.)
- **Always edit** template files in `templates/` directory instead
- **Regenerate** docs after template changes

### Code Style Conventions

- **Black:** 88-character line length
- **Type hints:** Required for all function signatures
- **Docstrings:** Use for public functions/classes; focus on complex logic
- **No wildcard imports:** Never use `from x import *`
- **Error handling:** Always handle exceptions in file/audio operations

### External Tools Required

- `fpcalc` - Chromaprint fingerprinting binary
- `ffprobe` - Audio metadata extraction (part of FFmpeg)

### Git Configuration

- SSH key alias: `github-ohtostado` (configured in ~/.ssh/config)
- Remote origin uses this alias

## Troubleshooting

### Common Issues

**Import errors:**

```bash
source .venv/bin/activate
pip install -r requirements.txt
```

**Chromaprint errors:**

```bash
# Ubuntu/Debian
sudo apt install libchromaprint-tools

# macOS
brew install chromaprint
```

**FFprobe errors:**

```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# macOS
brew install ffmpeg
```

## Session Context

### What Was Discussed

**Previous Sessions:**

1. Quality detection feature for identifying best quality files
2. Enhanced output with quality info, encoding details, similarity percentages
3. Color output for better UX (dark terminal background)
4. Sorting by similarity and proper tree characters
5. Multithreading implementation (SQLite cache, parallel fingerprinting)

**Current Session (Album Mode):**

1. Implemented album-level duplicate detection (Phases 1-3)
2. Fixed critical matching bug (tagged/untagged albums not grouping)
3. Implemented canonical matching approach (MB ID â†’ ID3 â†’ fingerprint)
4. Added match method display and confidence scoring
5. Created comprehensive test scenarios in test-albums/
6. Verified all test scenarios working correctly
7. Added fuzzy tag matching to future enhancements

### User Preferences

- Uses dark terminal background
- Values accessibility and readability
- Prefers industry-standard libraries over custom implementations
- Likes tasteful, not excessive, color usage
- Focuses on practical UX improvements
- Wants transparency in matching methodology

### Development Philosophy

- Quality over speed (all checks must pass)
- Follow established patterns in codebase
- Document changes thoroughly
- Test with real audio files
- Conventional commits with issue references

## How to Resume Development

1. **Clone repository:**

   ```bash
   git clone git@github-ohtostado:ohtostado/duperscooper.git
   cd duperscooper
   ```

2. **Setup environment:**

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   pip install -e .
   ```

3. **Switch to album mode branch:**

   ```bash
   git checkout feature/album-mode
   ```

4. **Verify setup:**

   ```bash
   # Test track mode
   .venv/bin/duperscooper test-audio/

   # Test album mode
   .venv/bin/duperscooper --album-mode test-albums/
   ```

5. **Check all quality tools work:**

   ```bash
   .venv/bin/black src/ tests/
   .venv/bin/ruff check src/ tests/
   .venv/bin/mypy src/
   .venv/bin/pytest tests/ -v
   ```

6. **Review documentation:**
   - Read `CLAUDE.md` (project-specific instructions)
   - Read `~/.claude/CLAUDE.md` (global development guidelines)
   - Review recent commits: `git log --oneline -10`
   - Review test scenarios: `cat test-albums/TEST-SCENARIOS.md`

## Files Modified in Recent Sessions

### Session 1-3: Quality, Color, Display (Merged to main)

- `src/duperscooper/hasher.py` - Metadata extraction, quality scoring
- `src/duperscooper/finder.py` - Quality detection, color output, sorting
- `src/duperscooper/__main__.py` - All output formats enhanced
- `pyproject.toml` - Added colorama dependency
- `requirements.txt` - Added colorama==0.4.6

### Session 4: Multithreading (Merged to main)

- `src/duperscooper/cache.py` - NEW: Cache backend interface
- `src/duperscooper/hasher.py` - Refactored for CacheBackend
- `src/duperscooper/finder.py` - ThreadPoolExecutor, ETA
- `src/duperscooper/__main__.py` - Added --workers, --cache-backend
- `tests/test_cache.py` - NEW: 16 unit tests

### Session 5: Album Mode (Current - feature/album-mode branch)

**Phase 1:**

- `src/duperscooper/album.py` - NEW: Album dataclass, AlbumScanner, AlbumDuplicateFinder
- `src/duperscooper/__main__.py` - Added --album-mode, --album-match-strategy

**Phase 2:**

- `src/duperscooper/album.py` - Matching strategies, similarity calculation

**Phase 3:**

- `src/duperscooper/album.py` - Canonical matching, confidence scoring, match_method field
- `src/duperscooper/cache.py` - Album cache schema (get_album, set_album methods)
- `src/duperscooper/__main__.py` - Enhanced album output formats
- `CLAUDE.md` - Added album mode documentation and fuzzy matching future phase

**Test Infrastructure:**

- `test-albums/` - 21 test folders created
- `test-albums/TEST-SCENARIOS.md` - NEW: Test documentation

## Contact & Resources

- **GitHub Repository:** <https://github.com/ohtostado/duperscooper>
- **Issues:** <https://github.com/ohtostado/duperscooper/issues>
- **Python Version:** 3.8+ (developed on 3.13)
- **License:** See LICENSE file

---

**Note for Claude:** This state file provides complete context to resume development. Read this file first, then review `CLAUDE.md` for project conventions, then check recent git history. The album mode feature is currently on `feature/album-mode` branch with Phases 1-3 complete and all test scenarios verified.
